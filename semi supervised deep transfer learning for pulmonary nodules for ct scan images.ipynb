{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c95191",
   "metadata": {},
   "source": [
    "# loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cec8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Step 1.1: Load the Iraq oncology dataset (unlabeled)\n",
    "iraq_dataset_path = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\2\\Unlabelled\"\n",
    "iraq_images = []\n",
    "desired_width = 224  # Replace with the desired width\n",
    "desired_height = 224 \n",
    "for filename in os.listdir(iraq_dataset_path):\n",
    "    image_path = os.path.join(iraq_dataset_path, filename)\n",
    "    image = cv2.imread(image_path)  # Load the image using OpenCV\n",
    "    # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "    image = cv2.resize(image, (desired_width, desired_height))  # Replace desired_width and desired_height with the desired size\n",
    "    iraq_images.append(image)\n",
    "    \n",
    "iraq_images = np.array(iraq_images)\n",
    "\n",
    "\n",
    "# Step 1.2: Load the CT-Scan images dataset (labeled)\n",
    "ct_scan_dataset_path = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\"\n",
    "labeled_images = []\n",
    "labels = []\n",
    "for label in ['Benign cases', 'Malignant cases']:\n",
    "    label_path = os.path.join(ct_scan_dataset_path, label)\n",
    "    for filename in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, filename)\n",
    "        image = cv2.imread(image_path)  # Load the image using OpenCV\n",
    "        # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "        image = cv2.resize(image, (desired_width, desired_height))  # Replace desired_width and desired_height with the desired size\n",
    "        labeled_images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "labeled_images = np.array(labeled_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure the images and labels are properly paired\n",
    "assert len(labeled_images) == len(labels), \"Number of images and labels should be the same\"\n",
    "\n",
    "print(\"Unlabeled dataset shape:\", iraq_images.shape)\n",
    "print(\"Labeled dataset shape:\", labeled_images.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ed399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display some images from the Iraq oncology dataset\n",
    "num_images_displayed = 5  # Number of images to display\n",
    "for i in range(num_images_displayed):\n",
    "    image = iraq_images[i]\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title('Iraq Oncology Image')\n",
    "plt.show()\n",
    "\n",
    "# Display some images from the CT-Scan images dataset\n",
    "num_images_displayed = 5  # Number of images to display\n",
    "for i in range(num_images_displayed):\n",
    "    image = labeled_images[i]\n",
    "    label = labels[i]\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title('CT-Scan Image - {}'.format(label))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b1721",
   "metadata": {},
   "source": [
    "# augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b819442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Define the data augmentation parameters\n",
    "augmentation_params = {\n",
    "    'rotation_range': 20,       # Random rotation (Â±20 degrees)\n",
    "    'width_shift_range': 0.1,   # Random horizontal shift\n",
    "    'height_shift_range': 0.1,  # Random vertical shift\n",
    "    'shear_range': 0.1,         # Shear transformation\n",
    "    'zoom_range': 0.1,          # Random zoom\n",
    "    'horizontal_flip': True,    # Horizontal flip\n",
    "    'fill_mode': 'nearest'      # Fill mode for newly created pixels\n",
    "}\n",
    "\n",
    "# Create an ImageDataGenerator with augmentation parameters\n",
    "data_augmentor = ImageDataGenerator(**augmentation_params)\n",
    "\n",
    "# Define the output directory to save the augmented images\n",
    "output_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\\augmented\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Apply data augmentation and save the generated images\n",
    "for i in range(len(labeled_images)):\n",
    "    image = labeled_images[i]\n",
    "    label = labels[i]\n",
    "    label_dir = os.path.join(output_dir, label)\n",
    "    if not os.path.exists(label_dir):\n",
    "        os.makedirs(label_dir)\n",
    "    img_gen = data_augmentor.flow(np.expand_dims(image, axis=0), batch_size=1, save_to_dir=label_dir, save_prefix='aug', save_format='png')\n",
    "    for _ in range(5):  # Generate 5 augmented images per original image\n",
    "        augmented_img = next(img_gen)[0].astype(np.uint8)\n",
    "        # You can perform additional preprocessing or saving steps if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cfa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"augmentation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2.2: Check for data imbalances\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "# Visualize the class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(unique_labels, counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Print the class distribution\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Class: {label}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c1e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c249616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2.2: Check for data imbalances\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "# Visualize the class distribution before oversampling\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(unique_labels, counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution (Before Oversampling)')\n",
    "plt.show()\n",
    "\n",
    "# Apply oversampling to balance the dataset\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "labeled_images_reshaped = labeled_images.reshape(-1, labeled_images.shape[1]*labeled_images.shape[2]*labeled_images.shape[3])\n",
    "labeled_images_resampled, labels_resampled = ros.fit_resample(labeled_images_reshaped, labels)\n",
    "\n",
    "# Convert back to the original image shape\n",
    "labeled_images_resampled = labeled_images_resampled.reshape(-1, labeled_images.shape[1], labeled_images.shape[2], labeled_images.shape[3])\n",
    "\n",
    "# Visualize the class distribution after oversampling\n",
    "unique_labels_resampled, counts_resampled = np.unique(labels_resampled, return_counts=True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(unique_labels_resampled, counts_resampled)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution (After Oversampling)')\n",
    "plt.show()\n",
    "\n",
    "# Print the class distribution after oversampling\n",
    "for label, count in zip(unique_labels_resampled, counts_resampled):\n",
    "    print(f\"Class: {label}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc37d96",
   "metadata": {},
   "source": [
    "# segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the directory containing the augmented images\n",
    "input_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\\augmented\"\n",
    "\n",
    "# Define the directory to save the segmented ROIs\n",
    "output_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\\segmented\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Loop through the augmented images\n",
    "for label in os.listdir(input_dir):\n",
    "    label_dir = os.path.join(input_dir, label)\n",
    "    for filename in os.listdir(label_dir):\n",
    "        image_path = os.path.join(label_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply thresholding to segment the lung region\n",
    "        _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a blank mask to draw the segmented ROIs\n",
    "        mask = np.zeros_like(image)\n",
    "\n",
    "        # Loop through the contours and draw the segmented ROIs on the mask\n",
    "        for contour in contours:\n",
    "            # Skip small contours\n",
    "            if cv2.contourArea(contour) < 100:\n",
    "                continue\n",
    "            # Draw the contour on the mask\n",
    "            cv2.drawContours(mask, [contour], -1, (0, 255, 0), thickness=cv2.FILLED)\n",
    "\n",
    "        # Apply the mask to the original image to extract the segmented ROIs\n",
    "        segmented_roi = cv2.bitwise_and(image, mask)\n",
    "\n",
    "        # Save the segmented ROI to the output directory\n",
    "        output_path = os.path.join(output_dir, label)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        output_filename = os.path.splitext(filename)[0] + '_segmented.png'\n",
    "        output_image_path = os.path.join(output_path, output_filename)\n",
    "        cv2.imwrite(output_image_path, segmented_roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the directory containing the augmented images\n",
    "input_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\\augmented\"\n",
    "\n",
    "# Define the directory to save the segmented ROIs\n",
    "output_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\\segmented\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Loop through the augmented images\n",
    "for label in os.listdir(input_dir):\n",
    "    label_dir = os.path.join(input_dir, label)\n",
    "    for filename in os.listdir(label_dir):\n",
    "        image_path = os.path.join(label_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply thresholding to segment the lung region\n",
    "        _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a blank mask to draw the segmented ROIs\n",
    "        mask = np.zeros_like(image)\n",
    "\n",
    "        # Loop through the contours and draw the segmented ROIs on the mask\n",
    "        for contour in contours:\n",
    "            # Skip small contours\n",
    "            if cv2.contourArea(contour) < 100:\n",
    "                continue\n",
    "            # Draw the contour on the mask\n",
    "            cv2.drawContours(mask, [contour], -1, (0, 255, 0), thickness=cv2.FILLED)\n",
    "\n",
    "        # Apply the mask to the original image to extract the segmented ROIs\n",
    "        segmented_roi = cv2.bitwise_and(image, mask)\n",
    "\n",
    "        # Save the segmented ROI to the output directory\n",
    "        output_path = os.path.join(output_dir, label)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        output_filename = os.path.splitext(filename)[0] + '_segmented.png'\n",
    "        output_image_path = os.path.join(output_path, output_filename)\n",
    "        cv2.imwrite(output_image_path, segmented_roi)\n",
    "\n",
    "        # Display the original image and segmented ROI\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        axs[0].set_title('Augmented Image')\n",
    "        axs[0].axis('off')\n",
    "        axs[1].imshow(cv2.cvtColor(segmented_roi, cv2.COLOR_BGR2RGB))\n",
    "        axs[1].set_title('Segmented ROI')\n",
    "        axs[1].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c850255",
   "metadata": {},
   "source": [
    "# Build VGG16/EfficientNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450be792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input directory for the segmented dataset\n",
    "segmented_dataset_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\\segmented\"\n",
    "\n",
    "# Set the output directory to save the trained model\n",
    "output_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\"\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 2\n",
    "\n",
    "# Set the desired input shape for the model\n",
    "input_shape = (224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the segmented dataset\n",
    "labeled_images = []\n",
    "labels = []\n",
    "for label in ['Benign cases', 'Malignant cases']:\n",
    "    label_path = os.path.join(segmented_dataset_dir, label)\n",
    "    for filename in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "        image = cv2.resize(image, input_shape[:2])\n",
    "        labeled_images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "labeled_images = np.array(labeled_images)\n",
    "\n",
    "# Encode the string labels into numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Convert the labels to one-hot encoded vectors\n",
    "labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(len(labeled_images))\n",
    "np.random.shuffle(indices)\n",
    "labeled_images = labeled_images[indices]\n",
    "labels = labels[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "#base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Build the model architecture\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a215da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Define the model checkpoint to save the best model during training\n",
    "checkpoint = ModelCheckpoint(os.path.join(output_dir, 'best_model.h5'), monitor='val_accuracy',\n",
    "                             save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(labeled_images, labels, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_split=0.2, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe55a31",
   "metadata": {},
   "source": [
    "# removing last few layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79421bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfe82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input directory for the segmented dataset\n",
    "segmented_dataset_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\\segmented\"\n",
    "\n",
    "# Set the output directory to save the trained model\n",
    "output_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\"\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 2\n",
    "\n",
    "# Set the desired input shape for the model\n",
    "input_shape = (224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ac4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Load the segmented dataset\n",
    "labeled_images = []\n",
    "labels = []\n",
    "for label in ['Benign cases', 'Malignant cases']:\n",
    "    label_path = os.path.join(segmented_dataset_dir, label)\n",
    "    for filename in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "        image = cv2.resize(image, input_shape[:2])\n",
    "        labeled_images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "labeled_images = np.array(labeled_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert the labels to binary format (0 for benign, 1 for malignant)\n",
    "labels = np.where(labels == 'Benign cases', 0, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(labeled_images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86778a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "#base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Remove the last few layers from the base model\n",
    "x = base_model.layers[-1].output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Add new layers for binary classification\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the modified model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c62861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Define the model checkpoint to save the best model during training\n",
    "checkpoint = ModelCheckpoint(os.path.join(output_dir, 'best_model.h5'), monitor='val_accuracy',\n",
    "                             save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(labeled_images, labels, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_split=0.2, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776473f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model saved during training\n",
    "model.load_weights(os.path.join(output_dir, 'best_model.h5'))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).flatten()\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a108d8e2",
   "metadata": {},
   "source": [
    "# Applying SSL algorithm Apply Mean Teacher Algo then labelling the unlabelled data by using pseudo labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82807ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input directory for the unlabeled data\n",
    "unlabeled_dataset_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\2\\Unlabelled\"\n",
    "\n",
    "# Set the output directory to save the pseudo-labeled data\n",
    "output_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\2\\pseudo-label\"\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 2\n",
    "\n",
    "# Set the desired input shape for the model\n",
    "input_shape = (224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "#base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Build the model architecture\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_weights(\"trained_model/best_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ad16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Loop through the unlabeled data\n",
    "for filename in os.listdir(unlabeled_dataset_dir):\n",
    "    image_path = os.path.join(unlabeled_dataset_dir, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "    image = cv2.resize(image, input_shape[:2])\n",
    "\n",
    "    # Perform inference to get the model's prediction\n",
    "    pred = model.predict(np.expand_dims(image, axis=0))\n",
    "    label = np.argmax(pred)\n",
    "\n",
    "    # Save the pseudo-labeled data into the output directory\n",
    "    output_path = os.path.join(output_dir, f\"label_{label}\")\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    output_filename = f\"pseudo_label_{label}_{filename}\"\n",
    "    output_image_path = os.path.join(output_path, output_filename)\n",
    "    cv2.imwrite(output_image_path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2077f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4feed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input directories for the labeled and pseudo-labeled data\n",
    "labeled_dataset_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\"\n",
    "pseudo_labeled_dataset_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\2\\pseudo-label\"\n",
    "\n",
    "# Set the output directory to save the trained model\n",
    "output_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\combined_validation\"\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 2\n",
    "\n",
    "# Set the desired input shape for the model\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Set the portion of labeled and pseudo-labeled data to use for the combined validation set\n",
    "validation_split = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5157425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled data\n",
    "labeled_images = []\n",
    "labels = []\n",
    "for label in ['Benign cases', 'Malignant cases']:\n",
    "    label_path = os.path.join(labeled_dataset_dir, label)\n",
    "    for filename in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "        image = cv2.resize(image, input_shape[:2])\n",
    "        labeled_images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "labeled_images = np.array(labeled_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert the labels to binary format (0 for benign, 1 for malignant)\n",
    "labels = np.where(labels == 'Benign cases', 0, 1)\n",
    "\n",
    "# Load the pseudo-labeled data\n",
    "pseudo_labeled_images = []\n",
    "pseudo_labels = []\n",
    "for label_dir in os.listdir(pseudo_labeled_dataset_dir):\n",
    "    label_path = os.path.join(pseudo_labeled_dataset_dir, label_dir)\n",
    "    label = int(label_dir.split(\"_\")[-1])  # Extract the pseudo-label from the folder name\n",
    "    for filename in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "        image = cv2.resize(image, input_shape[:2])\n",
    "        pseudo_labeled_images.append(image)\n",
    "        pseudo_labels.append(label)\n",
    "\n",
    "pseudo_labeled_images = np.array(pseudo_labeled_images)\n",
    "pseudo_labels = np.array(pseudo_labels)\n",
    "\n",
    "# Combine the labeled and pseudo-labeled data\n",
    "combined_images = np.concatenate((labeled_images, pseudo_labeled_images), axis=0)\n",
    "combined_labels = np.concatenate((labels, pseudo_labels), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d209d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels,\n",
    "                                                  test_size=validation_split, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of classes\n",
    "num_classes = 2  # Update this according to your dataset\n",
    "\n",
    "# Initialize the base model and build the model architecture\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "\n",
    "# Define the batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Define the model checkpoint to save the best model during training\n",
    "checkpoint = ModelCheckpoint(os.path.join(output_dir, 'best_model.h5'), monitor='val_accuracy',\n",
    "                             save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Train the model on the combined labeled and pseudo-labeled data\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(X_val, y_val), callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35df5a38",
   "metadata": {},
   "source": [
    "# fine tuning combine data and fit model on combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8fbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660bfbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input directories for the labeled and pseudo-labeled data\n",
    "labeled_dataset_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\"\n",
    "pseudo_labeled_dataset_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\2\\pseudo-label\"\n",
    "\n",
    "# Set the output directory to save the trained model\n",
    "output_dir = r\"C:\\Users\\ADMIN\\Desktop\\techieyan projects\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\combined_data\"\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 2\n",
    "\n",
    "# Set the desired input shape for the model\n",
    "input_shape = (224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffa911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled data\n",
    "labeled_images = []\n",
    "labels = []\n",
    "for label in ['Benign cases', 'Malignant cases']:\n",
    "    label_path = os.path.join(labeled_dataset_dir, label)\n",
    "    for filename in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "        image = cv2.resize(image, input_shape[:2])\n",
    "        labeled_images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "labeled_images = np.array(labeled_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert the labels to binary format (0 for benign, 1 for malignant)\n",
    "labels = np.where(labels == 'Benign cases', 0, 1)\n",
    "\n",
    "# Load the pseudo-labeled data\n",
    "pseudo_labeled_images = []\n",
    "pseudo_labels = []\n",
    "for label_dir in os.listdir(pseudo_labeled_dataset_dir):\n",
    "    label_path = os.path.join(pseudo_labeled_dataset_dir, label_dir)\n",
    "    label = int(label_dir.split(\"_\")[-1])  # Extract the pseudo-label from the folder name\n",
    "    for filename in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "        image = cv2.resize(image, input_shape[:2])\n",
    "        pseudo_labeled_images.append(image)\n",
    "        pseudo_labels.append(label)\n",
    "\n",
    "pseudo_labeled_images = np.array(pseudo_labeled_images)\n",
    "pseudo_labels = np.array(pseudo_labels)\n",
    "\n",
    "# Combine the labeled and pseudo-labeled data\n",
    "combined_images = np.concatenate((labeled_images, pseudo_labeled_images), axis=0)\n",
    "combined_labels = np.concatenate((labels, pseudo_labels), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15df4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(combined_images, combined_labels,\n",
    "                                                    test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2716cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "# base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Build the model architecture\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "\n",
    "# Define the batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Define the model checkpoint to save the best model during training\n",
    "checkpoint = ModelCheckpoint(os.path.join(output_dir, 'best_model.h5'), monitor='val_accuracy',\n",
    "                             save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Train the model on the combined labeled and pseudo-labeled data\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(X_test, y_test), callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2520ce",
   "metadata": {},
   "source": [
    "# evaluating the model performance on combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f028eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(output_dir, 'best_model.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c998e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(num_classes)\n",
    "plt.xticks(tick_marks, ['Benign', 'Malignant'])\n",
    "plt.yticks(tick_marks, ['Benign', 'Malignant'])\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "\n",
    "# Add labels to the plot\n",
    "thresh = conf_matrix.max() / 2\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, format(conf_matrix[i, j], 'd'), ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot the classification report metrics\n",
    "precision = report.split('\\n')[2].split()[1:]\n",
    "recall = report.split('\\n')[3].split()[1:]\n",
    "f1_score = report.split('\\n')[4].split()[1:]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "x = np.arange(len(precision))\n",
    "bar_width = 0.2\n",
    "plt.bar(x, precision, width=bar_width, label='Precision')\n",
    "plt.bar(x + bar_width, recall, width=bar_width, label='Recall')\n",
    "plt.bar(x + 2 * bar_width, f1_score, width=bar_width, label='F1-score')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Classification Metrics')\n",
    "plt.xticks(x + bar_width, ['Benign', 'Malignant'])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(['Accuracy'], [accuracy])\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4fbb64",
   "metadata": {},
   "source": [
    "# CoSSL Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b343ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Set the input directories for the labeled and pseudo-labeled data\n",
    "labeled_dataset_dir = r\"C:\\Users\\ADMIN\\Desktop\\Techieyan\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\1\\CT-Scan Images\"\n",
    "pseudo_labeled_dataset_dir = r\"C:\\Users\\ADMIN\\Desktop\\Techieyan\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\Dataset\\2\\pseudo-label\"\n",
    "\n",
    "# Set the output directory to save the trained model\n",
    "output_dir = r\"C:\\Users\\ADMIN\\Desktop\\Techieyan\\semi supervised learning deep transfer learning for pulomanry nodules detetction using ct images\\combined_data\"\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 2\n",
    "\n",
    "# Set the desired input shape for the model\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Set the portion of labeled and pseudo-labeled data to use for the combined validation set\n",
    "validation_split = 0.2\n",
    "\n",
    "# Load the labeled data\n",
    "labeled_images = []\n",
    "labels = []\n",
    "for label in ['Benign cases', 'Malignant cases']:\n",
    "    label_path = os.path.join(labeled_dataset_dir, label)\n",
    "    for filename in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "        image = cv2.resize(image, input_shape[:2])\n",
    "        labeled_images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "labeled_images = np.array(labeled_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert the labels to binary format (0 for benign, 1 for malignant)\n",
    "labels = np.where(labels == 'Benign cases', 0, 1)\n",
    "\n",
    "# Load the pseudo-labeled data\n",
    "pseudo_labeled_images = []\n",
    "pseudo_labels = []\n",
    "for label_dir in os.listdir(pseudo_labeled_dataset_dir):\n",
    "    label_path = os.path.join(pseudo_labeled_dataset_dir, label_dir)\n",
    "    label = int(label_dir.split(\"_\")[-1])  # Extract the pseudo-label from the folder name\n",
    "    for filename in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        # Preprocess the image if needed (e.g., resizing, normalization)\n",
    "        image = cv2.resize(image, input_shape[:2])\n",
    "        pseudo_labeled_images.append(image)\n",
    "        pseudo_labels.append(label)\n",
    "\n",
    "pseudo_labeled_images = np.array(pseudo_labeled_images)\n",
    "pseudo_labels = np.array(pseudo_labels)\n",
    "\n",
    "# Combine the labeled and pseudo-labeled data\n",
    "combined_images = np.concatenate((labeled_images, pseudo_labeled_images), axis=0)\n",
    "combined_labels = np.concatenate((labels, pseudo_labels), axis=0)\n",
    "\n",
    "# Split the combined data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels,\n",
    "                                                  test_size=validation_split, random_state=42)\n",
    "\n",
    "# Initialize the base model and build the model architecture\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "\n",
    "# Define the batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Define the model checkpoint to save the best model during training\n",
    "checkpoint = ModelCheckpoint(os.path.join(output_dir, 'best_model.h5'), monitor='val_accuracy',\n",
    "                             save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Train the model on the combined labeled and pseudo-labeled data\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(X_val, y_val), callbacks=[checkpoint])\n",
    "\n",
    "# Load the best model's weights\n",
    "model.load_weights(os.path.join(output_dir, 'best_model.h5'))\n",
    "\n",
    "# Evaluate the model on the test (or validation) set\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert the integer labels back to original class labels\n",
    "class_labels = ['Benign', 'Malignant']\n",
    "y_val_labels = np.array([class_labels[label] for label in y_val])\n",
    "y_pred_labels = np.array([class_labels[label] for label in y_pred_classes])\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_val_labels, y_pred_labels)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val_labels, y_pred_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.sum(y_pred_classes == y_val) / len(y_val)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(num_classes)\n",
    "plt.xticks(tick_marks, ['Benign', 'Malignant'])\n",
    "plt.yticks(tick_marks, ['Benign', 'Malignant'])\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "\n",
    "# Add labels to the plot\n",
    "thresh = conf_matrix.max() / 2\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, format(conf_matrix[i, j], 'd'), ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot the classification report metrics\n",
    "precision = report.split('\\n')[2].split()[1:]\n",
    "recall = report.split('\\n')[3].split()[1:]\n",
    "f1_score = report.split('\\n')[4].split()[1:]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "x = np.arange(len(precision))\n",
    "bar_width = 0.2\n",
    "plt.bar(x, precision, width=bar_width, label='Precision')\n",
    "plt.bar(x + bar_width, recall, width=bar_width, label='Recall')\n",
    "plt.bar(x + 2 * bar_width, f1_score, width=bar_width, label='F1-score')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Classification Metrics')\n",
    "plt.xticks(x + bar_width, ['Benign', 'Malignant'])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(['Accuracy'], [accuracy])\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f0a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
